{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RISHIVEER YADAV\\AppData\\Local\\Programs\\Python\\Python39\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3Q) KNN and ANN\n",
    "In this question we are asked to implement KNN and ANN from scratch given input embeddings\n",
    "\n",
    "## 3.1) KNN\n",
    "We are asked to implement KNN from scratch, the inputs are a set of embeddings. Given a query, k and a distance metric, it should return the indices of the k nearest neighbours from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    a_sq = np.sum(a**2, axis=1, keepdims=True)\n",
    "    b_sq = np.sum(b**2, axis=1)\n",
    "    ab = np.dot(a, b.T)\n",
    "    return np.sqrt(a_sq - 2 * ab + b_sq)\n",
    "\n",
    "def cosine_distance(a, b):\n",
    "    a_norm = a / np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    b_norm = b / np.linalg.norm(b, axis=1, keepdims=True)\n",
    "    return 1 - np.dot(a_norm, b_norm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(database, query, k, distance_metric):\n",
    "    indices = []\n",
    "    if distance_metric == 'euclidean':\n",
    "        distance = euclidean_distance(query, database)\n",
    "    elif distance_metric == 'cosine':\n",
    "        distance = cosine_distance(query, database)\n",
    "    else:\n",
    "        raise ValueError(\"Distance Metric not supported. Use only Euclidean or Cosine distances\")\n",
    "    indices.append(np.argsort(distance, axis=1)[:, :k])\n",
    "    return np.vstack(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(database, labels, query, k, distance_metric):\n",
    "    neighbour_indices = knn(database, query, k, distance_metric)\n",
    "    neighbour_labels = labels[neighbour_indices]\n",
    "    predictions = np.array([np.bincount(neighbour).argmax() for neighbour in neighbour_labels])\n",
    "    return predictions\n",
    "\n",
    "def mean_reciprocal_rank(ranked_indices, query_labels, database_labels):\n",
    "    mrr_values = []\n",
    "    for i, (ranks, true_label) in enumerate(zip(ranked_indices, query_labels)):\n",
    "        # Find the first occurrence of the correct class\n",
    "        correct_indices = np.where(database_labels[ranks] == true_label)[0]\n",
    "        if len(correct_indices) > 0:\n",
    "            mrr_values.append(1.0 / (correct_indices[0] + 1))\n",
    "        else:\n",
    "            mrr_values.append(0.0)\n",
    "    return np.mean(mrr_values)\n",
    "\n",
    "def precision_at_k(ranked_indices, query_labels, database_labels, k=100):\n",
    "    precisions = []\n",
    "    for ranks, true_label in zip(ranked_indices, query_labels):\n",
    "        retrieved_labels = database_labels[ranks[:k]]\n",
    "        precisions.append(np.sum(retrieved_labels == true_label) / k)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "def hit_rate(ranked_indices, query_labels, database_labels):\n",
    "    hits = []\n",
    "    for ranks, true_label in zip(ranked_indices, query_labels):\n",
    "        retrieved_labels = database_labels[ranks]\n",
    "        hits.append(1 if true_label in retrieved_labels else 0)\n",
    "    return np.mean(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_embeddings = torch.load('./SMAI A1/train_embeddings.pth',map_location=torch.device('cpu')).numpy()\n",
    "    test_embeddings = torch.load('./SMAI A1/test_embeddings.pth',map_location=torch.device('cpu')).numpy()\n",
    "    text_embeddings = torch.load('./SMAI A1/text_embedding.pth',map_location=torch.device('cpu')).numpy()\n",
    "    train_labels = torch.load('./SMAI A1/train_labels.pth',map_location=torch.device('cpu')).numpy()\n",
    "    test_labels = torch.load('./SMAI A1/test_labels.pth',map_location=torch.device('cpu')).numpy()\n",
    "\n",
    "    train_embeddings /= np.linalg.norm(train_embeddings, axis=1, keepdims=True)\n",
    "    test_embeddings /= np.linalg.norm(test_embeddings, axis=1, keepdims=True)\n",
    "    text_embeddings /= np.linalg.norm(text_embeddings, axis=1, keepdims=True)\n",
    "except Exception as e:\n",
    "    print('Error has occured:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 Euclidean Accuracy: 0.9048\n",
      "k=1 Cosine Accuracy: 0.9048\n",
      "k=5 Euclidean Accuracy: 0.9182\n",
      "k=5 Cosine Accuracy: 0.9182\n",
      "k=10 Euclidean Accuracy: 0.9194\n",
      "k=10 Cosine Accuracy: 0.9194\n",
      "Text-based Classification Accuracy: 0.8781\n",
      "\n",
      "Text-to-Image Retrieval Metrics:\n",
      "MRR: 1.0\n",
      "Precision@100: 0.974\n",
      "Hit Rate: 1.0\n",
      "\n",
      "Image-to-Image Retrieval Metrics:\n",
      "MRR: 0.934796151331504\n",
      "Precision@100: 0.841083\n",
      "Hit Rate: 0.9996\n"
     ]
    }
   ],
   "source": [
    "# Classification using train embeddings\n",
    "for k in [1, 5, 10]:\n",
    "    pred_euc = classify(train_embeddings, train_labels, test_embeddings, k, distance_metric='euclidean')\n",
    "    pred_cos = classify(train_embeddings, train_labels, test_embeddings, k, distance_metric='cosine')\n",
    "    print(f'k={k} Euclidean Accuracy:', accuracy_score(test_labels, pred_euc))\n",
    "    print(f'k={k} Cosine Accuracy:', accuracy_score(test_labels, pred_cos))\n",
    "\n",
    "# Classification using text embeddings\n",
    "pred_text = classify(text_embeddings, np.arange(10), test_embeddings, k=1, distance_metric='cosine')\n",
    "print('Text-based Classification Accuracy:', accuracy_score(test_labels, pred_text))\n",
    "\n",
    "# Text-to-Image Retrieval\n",
    "text_labels = np.arange(10)\n",
    "neighbours_text_to_image = knn(train_embeddings, text_embeddings, k=100, distance_metric='cosine')\n",
    "print('\\nText-to-Image Retrieval Metrics:')\n",
    "print('MRR:', mean_reciprocal_rank(neighbours_text_to_image, text_labels, train_labels))\n",
    "print('Precision@100:', precision_at_k(neighbours_text_to_image, text_labels, train_labels))\n",
    "print('Hit Rate:', hit_rate(neighbours_text_to_image, text_labels, train_labels))\n",
    "\n",
    "# Image-to-Image Retrieval\n",
    "neighbours_image_to_image = knn(train_embeddings, test_embeddings, k=100, distance_metric='cosine')\n",
    "print('\\nImage-to-Image Retrieval Metrics:')\n",
    "print('MRR:', mean_reciprocal_rank(neighbours_image_to_image, test_labels, train_labels))\n",
    "print('Precision@100:', precision_at_k(neighbours_image_to_image, test_labels, train_labels))\n",
    "print('Hit Rate:', hit_rate(neighbours_image_to_image, test_labels, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
